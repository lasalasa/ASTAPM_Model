{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766cbffd",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163c3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, explore and plot data\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# %matplotlib inline\n",
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Text pre-processing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Modeling\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffeef70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_core_utils.ipynb\n",
    "%run notebook_text_processor.ipynb\n",
    "%run notebook_core_mappers.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc3e6e",
   "metadata": {},
   "source": [
    "# Contacts (Common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b6d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "# factor_column_name = 'finding_description'\n",
    "\n",
    "# factors_columns = [ factor_column_name ]\n",
    "\n",
    "# narrative_columns = ['narrative_01', 'narrative_02']\n",
    "\n",
    "# filtered_columns = ['event_id'] + factors_columns + narrative_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca297f6",
   "metadata": {},
   "source": [
    "# Functions (Common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49de4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #----------- Data Manipulation Func ----------\n",
    "# def get_sample_size(df, percentage):\n",
    "#     row_count = df.shape[0]\n",
    "#     return round(row_count * (percentage / 100))\n",
    "\n",
    "# def get_data(ds_name):\n",
    "\n",
    "#     path_prefix = '../data/local_ex/astapm'\n",
    "\n",
    "#     asrs = pd.read_csv(f'{path_prefix}/{ds_name}/{ds_name}.csv', low_memory=False)\n",
    "#     asrs_narrative = pd.read_csv(f'{path_prefix}/{ds_name}/{ds_name}_narrative.csv', low_memory=False)\n",
    "#     asrs_factors = pd.read_csv(f'{path_prefix}/{ds_name}/{ds_name}_safety_factors.csv', low_memory=False)\n",
    "\n",
    "#     data_df = pd.merge(asrs, asrs_narrative, on='event_id', how='left')\n",
    "#     data_df = pd.merge(data_df, asrs_factors, on='event_id', how='left')\n",
    "\n",
    "#     # data_df = data_df[data_df['year'] == 2023]\n",
    "#     # data_df = data_df[(data_df['year'] >= 2008) & (data_df['year'] <= 2023)]\n",
    "\n",
    "#     df = data_df[filtered_columns].copy()\n",
    "#     return df\n",
    "\n",
    "# # Function to vectorize the 'Combined_Factors' column\n",
    "# def get_X_vec(df, col_name):\n",
    "#     X = df[col_name]\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     X_vec = vectorizer.fit_transform(X)\n",
    "#     return X_vec, vectorizer\n",
    "\n",
    "# def get_Y_encoder(df, label):\n",
    "#     labels = df[label].values\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     Y = label_encoder.fit_transform(labels)\n",
    "#     print('Shape of label tensor:', Y.shape)\n",
    "#     return label_encoder, Y\n",
    "\n",
    "# #----------- Model Train/Predict Func---------\n",
    "# def train_LS(df, ds_name='asrs'):\n",
    "#     # Assuming 'data' contains 'Combined_Factors' and 'HFACS_Category_Value'\n",
    "#     ls_df = df.copy()\n",
    "\n",
    "#     # Step 1: Prepare the data (drop rows with missing values)\n",
    "#     ls_df = ls_df.dropna(subset=['HFACS_Category_Value', factor_column_name])\n",
    "\n",
    "#     # Encode the 'HFACS_Category_Value'\n",
    "#     label_encoder, y = get_Y_encoder(ls_df, 'HFACS_Category_Value')\n",
    "#     unmapped_encoder = label_encoder.transform(['Unmapped'])[0]\n",
    "    \n",
    "#     # Set unlabeled data points to -1 (required by LabelSpreading)\n",
    "#     y[y == unmapped_encoder] = -1\n",
    "\n",
    "#     # Step 2: Vectorize the 'Combined_Factors' column using TF-IDF\n",
    "#     X_vec, vectorizer = get_X_vec(ls_df, factor_column_name)\n",
    "\n",
    "#     # Step 3: Split the labeled data into train and test sets (for evaluation)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_vec[y != -1], y[y != -1], test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Step 4: Create and fit the LabelSpreading model using ALL data (labeled + unlabeled)\n",
    "#     label_prop_model = LabelSpreading()\n",
    "#     label_prop_model.fit(X_vec, y)\n",
    "\n",
    "#     # Step 5: Make predictions on the test set (only labeled data for evaluation)\n",
    "#     y_test_predict = label_prop_model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_test_predict)\n",
    "#     print(\"Accuracy on test data:\", accuracy)\n",
    "\n",
    "#     # Optionally show confusion matrix\n",
    "#     show_confusion_matrix(label_prop_model, X_test, y_test, label_encoder)\n",
    "\n",
    "#     # Step 6: Predict the labels for the full dataset (including unlabeled data)\n",
    "#     y_full_predict = label_prop_model.predict(X_vec)\n",
    "\n",
    "#     # Handle -1 predictions by replacing them with 'Unmapped'\n",
    "#     y_full_predict = np.where(y_full_predict == -1, unmapped_encoder, y_full_predict)\n",
    "\n",
    "#     # Decode the predicted labels back to their original categories\n",
    "#     y_decoded = label_encoder.inverse_transform(y_full_predict)\n",
    "\n",
    "#     # Add the predicted labels back to the DataFrame\n",
    "#     ls_df['HFACS_Category_Value_Predict'] = y_decoded\n",
    "\n",
    "#     save_model_LS(label_prop_model, vectorizer, label_encoder, unmapped_encoder, ds_name)\n",
    "\n",
    "#     return label_prop_model, label_encoder, unmapped_encoder, vectorizer\n",
    "\n",
    "# def predict_LS(df, ds_name='asrs', sample_size=0):\n",
    "\n",
    "#     model, vectorizer, label_encoder, unmapped_encoder = load_model_LS(ds_name)\n",
    "\n",
    "#     # New set of data for prediction\n",
    "#     if sample_size > 0:\n",
    "#         labeled_data =  df.tail(sample_size).copy()\n",
    "#     else:\n",
    "#         labeled_data =  df\n",
    "\n",
    "#     # Drop rows with NaN in 'Combined_Factors'\n",
    "#     labeled_data = labeled_data.dropna(subset=[factor_column_name])\n",
    "\n",
    "#     # Vectorize the new set of data\n",
    "#     # X_vec = get_LS_X(labeled_data)\n",
    "#     X_vec = vectorizer.transform(labeled_data[factor_column_name])  \n",
    "\n",
    "#     # Predict using the trained LabelSpreading model\n",
    "#     y = model.predict(X_vec)\n",
    "\n",
    "#     # Replace -1 values with 'Unmapped' placeholder\n",
    "#     y = np.where(y == -1, unmapped_encoder, y)\n",
    "\n",
    "#     # Decode the predicted labels\n",
    "#     y_decoded = label_encoder.inverse_transform(y)\n",
    "\n",
    "#     # Add predictions to the new DataFrame\n",
    "#     labeled_data['HFACS_Category_Value_Predict'] = y_decoded\n",
    "#     return labeled_data\n",
    "# #----------- Model Train/Predict Func---------\n",
    "\n",
    "# #----------- Visualization Func ----------\n",
    "# # Show Label Distribution\n",
    "# def show_label(df, label_col):\n",
    "#     plt.figure(figsize=(8,6))\n",
    "#     sns.countplot(df[label_col])\n",
    "#     plt.title('The distribution of Primary problem')\n",
    "\n",
    "# # confusion_matrix\n",
    "# def show_confusion_matrix(model, X_test, y_test, label_encoder):\n",
    "#     # Predict the classes for the test set\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     # Generate the confusion matrix\n",
    "#     conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#     # Plot the confusion matrix\n",
    "#     plt.figure(figsize=(10,8))\n",
    "#     sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.show()\n",
    "# #----------- Visualization Func ----------\n",
    "\n",
    "# #----------- Model Save/Load Func ----------\n",
    "# # https://www.analyticsvidhya.com/blog/2023/02/how-to-save-and-load-machine-learning-models-in-python-using-joblib-library/\n",
    "# def save_model_LS(model, vectorizer, label_encoder, unmapped_encoder, name):\n",
    "#     # Save both the model and vectorizer to a file\n",
    "#     dump_name = f'model_LS_{name}.pkl'\n",
    "#     joblib.dump((model, vectorizer, label_encoder, unmapped_encoder), dump_name)\n",
    "#     print(f\"{name} Model and vectorizer saved successfully\")\n",
    "\n",
    "# def load_model_LS(name):\n",
    "#     # Load both the model and vectorizer from the file\n",
    "#     dump_name = f'model_LS_{name}.pkl'\n",
    "#     model, vectorizer,label_encoder, unmapped_encoder = joblib.load(dump_name)\n",
    "#     print(\"Model and vectorizer loaded successfully\")\n",
    "#     return model, vectorizer, label_encoder, unmapped_encoder\n",
    "# #----------- Model Save/Load Func ----------\n",
    "\n",
    "# #------------- HFACS Mapping ----------\n",
    "# HFACS_DICTIONARY = {\n",
    "#     # Unmapped\n",
    "#     -1: ('Unmapped', 'Unmapped', 'Unmapped', 'Unmapped'),\n",
    "#     # Unsafe Acts\n",
    "#     111: ('Level 1', 'Unsafe acts', 'Errors', 'Decision/Skill-based/Perceptual Errors'),\n",
    "#     # 112: ('Level 1', 'Unsafe acts', 'Errors', 'Skill-based Errors'),\n",
    "#     # 113: ('Level 1', 'Unsafe acts', 'Errors', 'Perceptual Errors'),\n",
    "#     121: ('Level 1', 'Unsafe acts', 'Violations', 'Routine / Exceptional Violations'),\n",
    "#     # 122: ('Level 1', 'Unsafe acts', 'Violations', 'Exceptional Violations'),\n",
    "\n",
    "#     # Preconditions for Unsafe Acts\n",
    "#     211: ('Level 2', 'Preconditions for Unsafe Acts', 'Environmental Factors', 'Physical Environment'),\n",
    "#     212: ('Level 2', 'Preconditions for Unsafe Acts', 'Environmental Factors', 'Technological Environment'),\n",
    "#     221: ('Level 2', 'Preconditions for Unsafe Acts', 'Conditions of Operators', 'Adverse Mental State/Adverse Physiological State/Physical Limitations'),\n",
    "#     # 222: ('Level 2', 'Preconditions for Unsafe Acts', 'Conditions of Operators', 'Adverse Physiological State'),\n",
    "#     # 223: ('Level 2', 'Preconditions for Unsafe Acts', 'Conditions of Operators', 'Physical Limitations'),\n",
    "#     231: ('Level 2', 'Preconditions for Unsafe Acts', 'Personnel Factors', 'Crew Resource Management/Personal Readiness'),\n",
    "#     # 232: ('Level 2', 'Preconditions for Unsafe Acts', 'Personnel Factors', 'Personal Readiness'),\n",
    "    \n",
    "#     # Unsafe Supervision\n",
    "#     321: ('Level 3', 'Unsafe Supervision', 'Unsafe Supervision', 'Planned Inappropriate Operations'),\n",
    "#     311: ('Level 3', 'Unsafe Supervision', 'Unsafe Supervision', 'Inadequate Supervision'),\n",
    "#     331: ('Level 3', 'Unsafe Supervision', 'Unsafe Supervision', 'Failure to Correct Known Problems'),\n",
    "#     341: ('Level 3', 'Unsafe Supervision', 'Unsafe Supervision', 'Supervisory Violations'),\n",
    "    \n",
    "#     # Organizational Influences\n",
    "#     411: ('Level 4', 'Organizational Influences', 'Organizational Influences', 'Organizational Climate/Organizational Process/Resource Management'),\n",
    "#     # 421: ('Level 4', 'Organizational Influences', 'Organizational Influences', 'Organizational Process'),\n",
    "#     # 431: ('Level 4', 'Organizational Influences', 'Organizational Influences', 'Resource Management')\n",
    "# }\n",
    "# #------------- HFACS Mapping ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6baa291",
   "metadata": {},
   "source": [
    "# ASRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393ecc9",
   "metadata": {},
   "source": [
    "## Function | Variables | Constants (ASRS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3669a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #------------- ASRS Manual Mapping ----------\n",
    "# keyword_pf_mappings_asrs = {\n",
    "#     \"Aircraft\": 212,                                        # Preconditions for Unsafe Acts => Technological Environment\n",
    "#     \"Airport\": 211,                                         # Preconditions for Unsafe Acts => Physical Environment\n",
    "#     \"Airspace Structure\": 212,                              # Preconditions for Unsafe Acts => Technological Environment\n",
    "#     \"ATC Equipment / Nav Facility / Buildings\": 212,        # Preconditions for Unsafe Acts => Technological Environment\n",
    "#     \"Chart Or Publication\": 411, #421,                            # Organizational Influences => Organizational Process\n",
    "#     \"Company Policy\": 411,                                  # Organizational Influences => Organizational Climate\n",
    "#     \"Environment - Non Weather Related\": 211,               # Preconditions for Unsafe Acts => Physical Environment\n",
    "#     \"Equipment / Tooling\": 212,                             # Preconditions for Unsafe Acts => Technological Environment\n",
    "#     \"Human Factors\": 11,                                    # Unsafe Acts => Errors or Violations\n",
    "#     \"Incorrect / Not Installed / Unavailable Part\": 411, #431,    # Organizational Influences => Resource Management\n",
    "#     \"Logbook Entry\": 411, #421,                                   # Organizational Influences => Organizational Process\n",
    "#     \"Manuals\": 411, #421,                                         # Organizational Influences => Organizational Process\n",
    "#     \"MEL\": 411, #421,                                             # Organizational Influences => Organizational Process\n",
    "#     \"Procedure\": 411, #421,                                       # Organizational Influences => Organizational Process\n",
    "#     \"Software and Automation\": 212,                         # Preconditions for Unsafe Acts => Technological Environment\n",
    "#     \"Staffing\": 411, #431,                                        # Organizational Influences => Resource Management\n",
    "#     \"Weather\": 211                                          # Preconditions for Unsafe Acts => Physical Environment\n",
    "# }\n",
    "\n",
    "# # keyword_pf_balance_mappings_asrs = {\n",
    "# #     \"Aircraft\": 212,                                        # Preconditions for Unsafe Acts => Technological Environment\n",
    "# #     \"Airport\": 211,                                         # Preconditions for Unsafe Acts => Physical Environment\n",
    "# #     \"Airspace Structure\": 212,                              # Preconditions for Unsafe Acts => Technological Environment\n",
    "# #     \"ATC Equipment / Nav Facility / Buildings\": 212,        # Preconditions for Unsafe Acts => Technological Environment\n",
    "# #     \"Chart Or Publication\": 421,                            # Organizational Influences => Organizational Process\n",
    "# #     \"Company Policy\": 411,                                  # Organizational Influences => Organizational Climate\n",
    "# #     \"Environment - Non Weather Related\": 211,               # Preconditions for Unsafe Acts => Physical Environment\n",
    "# #     \"Equipment / Tooling\": 212,                             # Preconditions for Unsafe Acts => Technological Environment\n",
    "# #     \"Human Factors\": 11,                                    # Unsafe Acts => Errors or Violations\n",
    "# #     \"Incorrect / Not Installed / Unavailable Part\": 431,    # Organizational Influences => Resource Management\n",
    "# #     \"Logbook Entry\": 421,                                   # Organizational Influences => Organizational Process\n",
    "# #     \"Manuals\": 421,                                         # Organizational Influences => Organizational Process\n",
    "# #     \"MEL\": 421,                                             # Organizational Influences => Organizational Process\n",
    "# #     \"Procedure\": 421,                                       # Organizational Influences => Organizational Process\n",
    "# #     \"Software and Automation\": 212,                         # Preconditions for Unsafe Acts => Technological Environment\n",
    "# #     \"Staffing\": 431,                                        # Organizational Influences => Resource Management\n",
    "# #     \"Weather\": 211                                          # Preconditions for Unsafe Acts => Physical Environment\n",
    "# # }\n",
    "\n",
    "# keyword_hf_mappings_asrs = {\n",
    "#     \"Communication Breakdown\": 231,     # Preconditions for Unsafe Acts => Personnel Factors => Crew Resource Management)\n",
    "#     \"Confusion\": 111, #113,                   # Perceptual Errors\n",
    "#     \"Distraction\": 111, #112,                 # Skill-based Errors\n",
    "#     \"Fatigue\": 221,                     # Adverse Mental State\n",
    "#     \"Human-Machine Interface\": 212,     # Technological Environment\n",
    "#     # \"Other / Unknown\": (-1, -1, -1),  # General Error (Unspecified)\n",
    "#     \"Physiological - Other\": 221, #222,       # Adverse Physiological State\n",
    "#     \"Situational Awareness\": 221,       # Conditions of Operators → Adverse Mental State\n",
    "#     \"Time Pressure\": 221,               # Adverse Mental State\n",
    "#     \"Training / Qualification\": 111, #112,    # Personal Readiness\n",
    "#     \"Troubleshooting\": 111, #112,             # Skill-based Errors\n",
    "#     \"Workload\": 221                     # Adverse Mental State\n",
    "# }\n",
    "\n",
    "\n",
    "#------------- ASRS Manual Mapping ----------\n",
    "\n",
    "#------------- Manual Labeling Func ----------\n",
    "\n",
    "# keyword_hf_mappings_asrs = AUTO_LABELING_DICTIONARY[\"asrs\"][\"HF_DICTIONARY\"]\n",
    "# keyword_pf_mappings_asrs = AUTO_LABELING_DICTIONARY[\"asrs\"][\"PF_DICTIONARY\"]\n",
    "\n",
    "# HFACS_DICTIONARY = HFACS_DICTIONARY[\"hfacs\"]\n",
    "# factor_column_name = CoreUtils.get_constant()[\"FACTOR_COL_NAME\"]\n",
    "\n",
    "# def map_hf_asrs(factors):\n",
    "#     # Convert to lowercase for consistent keyword matching\n",
    "#     factors = str(factors).lower()\n",
    "\n",
    "#     split_factors = factors.split(':')\n",
    "#     if(len(split_factors) == 1):\n",
    "#         # Only include Human factor, map with # Skill-based Errors TODO Need to improve\n",
    "#         return 111 #112\n",
    "    \n",
    "#     for keyword, mapping in keyword_hf_mappings_asrs.items():\n",
    "#         # print(keyword.lower(), '=>>>', factors)\n",
    "#         if keyword.lower() in factors:  # Check if keyword is in the combined issues string\n",
    "#             # print(keyword.lower(), '=>>>', factors)\n",
    "#             return mapping\n",
    "#     return -1\n",
    "\n",
    "# # Function to map combined issues to HFACS based on keyword mappings\n",
    "# def map_hfacs_asrs(factors):\n",
    "#      # Convert to lowercase for consistent keyword matching\n",
    "#     factors = str(factors).lower()\n",
    "\n",
    "#     for keyword, mapping in keyword_pf_mappings_asrs.items():\n",
    "#         if keyword.lower() in factors:  # Check if keyword is in the combined issues string\n",
    "#             # print(keyword.lower(), '=>>>', factors)\n",
    "#             if(mapping == 11):\n",
    "#                 # print(mapping)\n",
    "#                 return map_hf_asrs(factors)\n",
    "#             return mapping\n",
    "#     return -1  # Default to unmapped if no match found\n",
    "\n",
    "# def manual_labeling_asrs(df, sample_size=0):\n",
    "\n",
    "#     # df_tail = df.tail(sample_size).copy()\n",
    "\n",
    "#     if sample_size > 0:\n",
    "#         df_tail =  df.sample(n=sample_size, random_state=42)\n",
    "#     else:\n",
    "#         df_tail = df\n",
    "        \n",
    "#     print('sample_size=', df_tail.shape)\n",
    "    \n",
    "#     df_tail.replace('', pd.NA, inplace=True)\n",
    "#     # print_column = ['ACN'] + factors_column\n",
    "\n",
    "#     # df_tail[print_column].value_counts()\n",
    "#     # df_tail.isnull().sum()\n",
    "\n",
    "#     # Load the dataset (update the file path as needed)\n",
    "#     data = df_tail.copy()\n",
    "#     # Apply the function to each 'Combined_Issues' row and map to HFACS\n",
    "#     data['HFACS_Category_Index'] = data[factor_column_name].apply(map_hfacs_asrs)\n",
    "\n",
    "#     # Split the 'HFACS_Mapped' into two new columns: 'HFACS_Category' and 'HFACS_Level'\n",
    "#     data['HFACS_Category_Value'] = data['HFACS_Category_Index'].apply(lambda x: HFACS_DICTIONARY[x][3])\n",
    "#     data['HFACS_Level'] = data['HFACS_Category_Index'].apply(lambda x: HFACS_DICTIONARY[x][0])\n",
    "\n",
    "#     # # Summarize the mapped HFACS categories and levels\n",
    "#     hfacs_summary = data.groupby(['HFACS_Category_Value']).size().reset_index(name='Count')\n",
    "#     print(hfacs_summary)\n",
    "#     return data\n",
    "\n",
    "# #------------- Manual Labeling Func ----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c101ec95",
   "metadata": {},
   "source": [
    "# NTSB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576716ff",
   "metadata": {},
   "source": [
    "## Function | Variables | Constants (NTSB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4adf65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- ASRS Manual Mapping ----------\n",
    "# keyword_mappings_ntsb = {\n",
    "#     # Unsafe Acts => Skill-based Errors\n",
    "#     \"Personnel issues-Task performance\": 112,\n",
    "#     # Unsafe Acts => Decision Errors\n",
    "#     \"Personnel issues-Action/decision\": 111,\n",
    "#      # Unsafe Acts => Perceptual Errors\n",
    "#     \"Personnel issues-Psychological-Perception/orientation/illusion\": 113,\n",
    "#     # Unsafe Acts => Violations\n",
    "#     \"Personnel issues-Miscellaneous-Intentional act\": 121,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Physical Environment\n",
    "#     'Environmental issues-Physical environment': 211,\n",
    "#     'Environmental issues-Conditions/weather/phenomena-Turbulence': 211,\n",
    "#     'Environmental issues-Task environment': 211,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Technological Environment\n",
    "#     'Environmental issues-Operating environment': 212,\n",
    "#     'Aircraft-Aircraft systems': 212,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Adverse Mental State\n",
    "#     'Personnel issues-Physical-Alertness/Fatigue': 221,\n",
    "#     'Personnel issues-Psychological-Attention/monitoring': 221,\n",
    "#     'Personnel issues-Psychological-Personality/attitude': 221,\n",
    "#     'Personnel issues-Psychological-Mental/emotional state': 221,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Adverse Physiological State\n",
    "#     'Personnel issues-Psychological': 222,\n",
    "#     'Personnel issues-Physical-Impairment/incapacitation': 222,\n",
    "#     'Personnel issues-Physical-Health/Fitness': 222,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Physical Limitations\n",
    "#     'Personnel issues-Physical-Sensory ability/limitation': 223,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Crew Resource Management\n",
    "#     'Lack of communication': 231,\n",
    "\n",
    "#     # Preconditions for Unsafe Acts => Personal Readiness\n",
    "#     \"Personnel issues-Experience/knowledge\": 232,\n",
    "\n",
    "#     # Organizational Influences => Organizational Climate\n",
    "#     'Organizational issues-Management-Culture': 411,\n",
    "#     'Organizational issues-Management-Communication (organizational)': 411,\n",
    "\n",
    "#     # Organizational Influences =>  Organizational Process\n",
    "#     'Organizational issues-Management-Scheduling':  421,\n",
    "#     'Organizational issues-Management-Policy/procedure':  421,\n",
    "#     'Organizational issues-Management-(general)-(general)-Operator':  421,\n",
    "#     'Organizational issues-Support/oversight/monitoring': 421,\n",
    "\n",
    "#     # Organizational Influences =>  Resource Management\n",
    "#     'Organizational issues-Management-Resources': 431,\n",
    "#     'Organizational issues-Development-Selection/certification/testing': 431,\n",
    "# }\n",
    "# #------------- ASRS Manual Mapping ----------\n",
    "\n",
    "# keyword_mappings_ntsb = AUTO_LABELING_DICTIONARY[\"ntsb\"]\n",
    "\n",
    "# # Function to map combined issues to HFACS based on keyword mappings\n",
    "# def map_hfacs_ntsb(factors):\n",
    "\n",
    "#      # Convert to lowercase for consistent keyword matching\n",
    "#     factors = str(factors).lower()\n",
    "\n",
    "#     for keyword, mapping in keyword_mappings_ntsb.items():\n",
    "#         # Check if keyword is in the factors string\n",
    "#         if keyword.lower() in factors:\n",
    "#             # print(keyword.lower(), '=>>>', factors)\n",
    "#             return mapping\n",
    "#      # Default to unmapped if no match found\n",
    "#     return -1\n",
    "\n",
    "# def manual_labeling_ntsb(df, sample_size):\n",
    "\n",
    "#     # df_tail = df.tail(sample_size).copy()\n",
    "\n",
    "#     df_tail = df.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "#     df_tail.replace('', pd.NA, inplace=True)\n",
    "#     # print_column = ['ACN'] + factors_column\n",
    "\n",
    "#     # df_tail[print_column].value_counts()\n",
    "#     # df_tail.isnull().sum()\n",
    "\n",
    "#     # Load the dataset (update the file path as needed)\n",
    "#     data = df_tail.copy()\n",
    "#     # Apply the function to each 'Combined_Issues' row and map to HFACS\n",
    "#     data['HFACS_Category_Index'] = data[factor_column_name].apply(map_hfacs_ntsb)\n",
    "\n",
    "#     # Split the 'HFACS_Mapped' into two new columns: 'HFACS_Category' and 'HFACS_Level'\n",
    "#     data['HFACS_Category_Value'] = data['HFACS_Category_Index'].apply(lambda x: HFACS_DICTIONARY[x][3])\n",
    "#     data['HFACS_Level'] = data['HFACS_Category_Index'].apply(lambda x: HFACS_DICTIONARY[x][0])\n",
    "\n",
    "#     # # Summarize the mapped HFACS categories and levels\n",
    "#     hfacs_summary = data.groupby(['HFACS_Category_Value']).size().reset_index(name='Count')\n",
    "#     print(hfacs_summary)\n",
    "#     return data\n",
    "\n",
    "# def train_LS_NTSB(df, factor_label_name='finding_description'):\n",
    "#     # Assuming 'data' contains 'Combined_Factors' and 'HFACS_Category_Value'\n",
    "#     ls_df = df.copy()\n",
    "\n",
    "#     # Step 1: Prepare the data (drop rows with missing values)\n",
    "#     ls_df = ls_df.dropna(subset=['HFACS_Category_Value', factor_label_name])\n",
    "\n",
    "#     # Encode the 'HFACS_Category_Value'\n",
    "#     label_encoder, y = get_Y_encoder(ls_df, 'HFACS_Category_Value')\n",
    "#     unmapped_encoder = label_encoder.transform(['Unmapped'])[0]\n",
    "    \n",
    "#     # Set unlabeled data points to -1 (required by LabelSpreading)\n",
    "#     y[y == unmapped_encoder] = -1\n",
    "\n",
    "#     # Step 2: Vectorize the 'Combined_Factors' column using TF-IDF\n",
    "#     X_vec, vectorizer = get_X_vec(ls_df, factor_label_name)\n",
    "\n",
    "#     # Step 3: Split the labeled data into train and test sets (for evaluation)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_vec[y != -1], y[y != -1], test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Step 4: Create and fit the LabelSpreading model using ALL data (labeled + unlabeled)\n",
    "#     label_prop_model = LabelSpreading()\n",
    "#     label_prop_model.fit(X_vec, y)\n",
    "\n",
    "#     # Step 5: Make predictions on the test set (only labeled data for evaluation)\n",
    "#     y_test_predict = label_prop_model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_test_predict)\n",
    "#     print(\"Accuracy on test data:\", accuracy)\n",
    "\n",
    "#     # Optionally show confusion matrix\n",
    "#     show_confusion_matrix(label_prop_model, X_test, y_test, label_encoder)\n",
    "\n",
    "#     # Step 6: Predict the labels for the full dataset (including unlabeled data)\n",
    "#     y_full_predict = label_prop_model.predict(X_vec)\n",
    "\n",
    "#     # Handle -1 predictions by replacing them with 'Unmapped'\n",
    "#     y_full_predict = np.where(y_full_predict == -1, unmapped_encoder, y_full_predict)\n",
    "\n",
    "#     # Decode the predicted labels back to their original categories\n",
    "#     y_decoded = label_encoder.inverse_transform(y_full_predict)\n",
    "\n",
    "#     # Add the predicted labels back to the DataFrame\n",
    "#     ls_df['HFACS_Category_Value_Predict'] = y_decoded\n",
    "\n",
    "#     return label_prop_model, label_encoder, unmapped_encoder, vectorizer\n",
    "\n",
    "# def predict_LS_NTSB(df, sample_size=0):\n",
    "\n",
    "#     model, vectorizer, label_encoder, unmapped_encoder = load_model_LS('ntsb')\n",
    "\n",
    "#     # New set of data for prediction\n",
    "#     if sample_size > 0:\n",
    "#         labeled_data =  df.tail(sample_size).copy()\n",
    "#     else:\n",
    "#         labeled_data =  df\n",
    "\n",
    "#     # Drop rows with NaN in 'Combined_Factors'\n",
    "#     labeled_data = labeled_data.dropna(subset=['finding_description'])\n",
    "\n",
    "#     # Vectorize the new set of data\n",
    "#     # X_vec = get_LS_X(labeled_data)\n",
    "#     X_vec = vectorizer.transform(labeled_data['finding_description'])  \n",
    "\n",
    "#     # Predict using the trained LabelSpreading model\n",
    "#     y = model.predict(X_vec)\n",
    "\n",
    "#     # Replace -1 values with 'Unmapped' placeholder\n",
    "#     y = np.where(y == -1, unmapped_encoder, y)\n",
    "\n",
    "#     # Decode the predicted labels\n",
    "#     y_decoded = label_encoder.inverse_transform(y)\n",
    "\n",
    "#     # Add predictions to the new DataFrame\n",
    "#     labeled_data['HFACS_Category_Value_Predict'] = y_decoded\n",
    "#     return labeled_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
